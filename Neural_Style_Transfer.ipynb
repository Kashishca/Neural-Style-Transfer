# Import necessary libraries
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.applications import VGG19
from tensorflow.keras.applications.vgg19 import preprocess_input
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.models import Model

# Load and preprocess images with resizing
def load_and_preprocess_image(image_path, max_dim=512):
    image = load_img(image_path, target_size=(max_dim, max_dim))
    image = img_to_array(image)
    image = np.expand_dims(image, axis=0)
    image = preprocess_input(image)
    return image

# Load content and style images
content_image_path = '/content/brad.jpeg'  # Replace with your content image path
style_image_path = '/content/VAN.jpeg'      # Replace with your style image path

content_image = load_and_preprocess_image(content_image_path)
style_image = load_and_preprocess_image(style_image_path)

# Display the images
def imshow(image, title=None):
    image = image * 127.5 + 127.5
    image = np.clip(image, 0, 255).astype('uint8')
    plt.imshow(image[0])
    if title:
        plt.title(title)
    plt.axis('off')

# Display original images before preprocessing
def display_original_image(image_path, title=None):
    image = load_img(image_path)
    plt.imshow(image)
    if title:
        plt.title(title)
    plt.axis('off')

plt.figure(figsize=(12, 12))
plt.subplot(1, 2, 1)
display_original_image(content_image_path, title='Content Image')

plt.subplot(1, 2, 2)
display_original_image(style_image_path, title='Style Image')
plt.show()

# Load VGG19 model
model = VGG19(include_top=False, weights='imagenet')
model.trainable = False

# Define content and style layers
content_layers = ['block5_conv2']
style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']

# Create models for content and style
content_model = Model(inputs=model.input, outputs=[model.get_layer(name).output for name in content_layers])
style_model = Model(inputs=model.input, outputs=[model.get_layer(name).output for name in style_layers])

# Compute content and style features
def get_features(model, input_tensor):
    outputs = model(input_tensor)
    return outputs

content_features = get_features(content_model, content_image)
style_features = get_features(style_model, style_image)

# Define the total loss function
def compute_loss(combined_image, content_features, style_features, content_weight=1e3, style_weight=1e-2):
    combined_content_features = get_features(content_model, combined_image)
    combined_style_features = get_features(style_model, combined_image)
    
    content_loss = tf.add_n([tf.reduce_mean((combined_content_features[i] - content_features[i]) ** 2) for i in range(len(content_features))])
    style_loss = tf.add_n([tf.reduce_mean((combined_style_features[i] - style_features[i]) ** 2) for i in range(len(style_features))])
    
    total_loss = content_weight * content_loss + style_weight * style_loss
    return total_loss

# Optimization loop
optimizer = tf.optimizers.Adam(learning_rate=0.02)

generated_image = tf.Variable(content_image, dtype=tf.float32)

@tf.function
def train_step():
    with tf.GradientTape() as tape:
        loss = compute_loss(generated_image, content_features, style_features)
    gradients = tape.gradient(loss, generated_image)
    optimizer.apply_gradients([(gradients, generated_image)])
    generated_image.assign(tf.clip_by_value(generated_image, -1.0, 1.0))

# Train the model
epochs = 10
steps_per_epoch = 100

for epoch in range(epochs):
    for step in range(steps_per_epoch):
        train_step()
        if step % 10 == 0:
            print(f"Epoch: {epoch+1}, Step: {step+1}, Loss: {compute_loss(generated_image, content_features, style_features).numpy()}")

# Display the generated image
plt.figure(figsize=(12, 12))
imshow(generated_image.read_value(), title='Generated Image')
plt.show()
